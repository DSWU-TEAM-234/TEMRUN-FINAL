package com.temrun_finalprojects.breathing.audio
import android.Manifest
import android.content.Context
import android.content.Intent
import android.content.pm.PackageManager
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.MediaRecorder
import android.os.Handler
import android.util.Log
import android.widget.Toast
import androidx.core.app.ActivityCompat
import com.temrun_finalprojects.MainActivity
import com.temrun_finalprojects.breathing.model.ModelInterpreter
import java.io.IOException

class AudioRecorder(private val context: Context) {
    private val handler = Handler()

    // ì‚¬ìš©ì ì„¤ì •ê°’ ì €ì¥ ë³€ìˆ˜ ì¶”ê°€
    /**
     * TODO: ì‚¬ìš©ì UIë‘ ì—°ê²°í•´ì•¼í•œë‹¤.
     * */
    private var userBpm: Int = 150
    private var userPattern: String = "2:1"
    private var userBreathingPattern: IntArray = intArrayOf(2, 1)

    fun setUserSettings(bpm: Int, pattern: String, breathingPattern: IntArray) {
        this.userBpm = bpm
        this.userPattern = pattern
        this.userBreathingPattern = breathingPattern
    }

    fun startRecording() {
        // ğŸ” ê¶Œí•œ ì²´í¬
        if (ActivityCompat.checkSelfPermission(context, Manifest.permission.RECORD_AUDIO)
            != PackageManager.PERMISSION_GRANTED
        ) {
            Toast.makeText(context, "ë…¹ìŒ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤", Toast.LENGTH_SHORT).show()
            return
        }

        Thread(Runnable {
            val recorder: AudioRecord
            try {
                recorder = AudioRecord(
                    MediaRecorder.AudioSource.MIC,
                    com.temrun_finalprojects.breathing.audio.AudioRecorder.Companion.SAMPLE_RATE,
                    AudioFormat.CHANNEL_IN_MONO,
                    AudioFormat.ENCODING_PCM_16BIT,
                    com.temrun_finalprojects.breathing.audio.AudioRecorder.Companion.BUFFER_SIZE * 2
                )
                recorder.startRecording()
                Log.d("AudioRecoder", "ìŠ¤íƒ€íŠ¸ ë¦¬ì½”ë”© ë¶€ë¶„ ë¬´ì‚¬ í†µê³¼.")
            } catch (e: SecurityException) {
                e.printStackTrace()
                handler.post {
                    Toast.makeText(
                        context,
                        "ë…¹ìŒ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤",
                        Toast.LENGTH_SHORT
                    ).show()
                }
                return@Runnable
            }

            val audioBuffer =
                ShortArray(com.temrun_finalprojects.breathing.audio.AudioRecorder.Companion.BUFFER_SIZE)
            while (true) {
                val read = recorder.read(
                    audioBuffer,
                    0,
                    com.temrun_finalprojects.breathing.audio.AudioRecorder.Companion.BUFFER_SIZE
                )
                if (read > 0) {
                    val audioFloat = FloatArray(read)
                    for (i in 0 until read) {
                        audioFloat[i] = audioBuffer[i] / 32768f
                    }

                    try {
                        processAudio(audioFloat)
                    } catch (e: IOException) {
                        throw RuntimeException(e)
                    }
                }

                try {
                    Thread.sleep((com.temrun_finalprojects.breathing.audio.AudioRecorder.Companion.RECORD_SECONDS * 1000).toLong())
                } catch (e: InterruptedException) {
                    e.printStackTrace()
                    break
                }
            }
        }).start()
    }

    @Throws(IOException::class)
    private fun processAudio(audioData: FloatArray) {
        val features: AudioProcessor.FeatureSet = AudioProcessor.extractFeatures(audioData)

        var finalPrediction: String = ""

        // Model1ê³¼ Model2 ìˆœì°¨ ì‹¤í–‰ ë¡œì§
        if (!ModelInterpreter.shouldUseModel2()) {
            // Model1 ë¨¼ì € ì‹¤í–‰
            val model1Result = ModelInterpreter.runModel1(context, features, userBpm, userPattern)

            if (model1Result == "ì •ìƒ") {
                Log.e("Model1", "ì •ìƒ í˜¸í¡ íŒ¨í„´")
//                finalPrediction = "ì •ìƒ í˜¸í¡ íŒ¨í„´ì…ë‹ˆë‹¤."
            } else {
                // ë¹„ì •ìƒì´ë©´ ì„ê³„ê°’ í™•ì¸
                if (ModelInterpreter.shouldUseModel2()) {
                    // ë¹„ì •ìƒì´ 5ë²ˆ ì´ìƒì´ë©´ Model2 ì‹¤í–‰
                    finalPrediction = ModelInterpreter.runModel2(context, features, userBpm, userBreathingPattern)
                    ModelInterpreter.resetAbnormalCount() // Model2 ì‹¤í–‰ í›„ ì¹´ìš´íŠ¸ ë¦¬ì…‹
                } else {
//                    finalPrediction = "í˜¸í¡ íŒ¨í„´ì— ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                }
            }
        } else {
            // ì´ë¯¸ ì„ê³„ê°’ì„ ë„˜ì—ˆìœ¼ë©´ ë°”ë¡œ Model2 ì‹¤í–‰
            finalPrediction = ModelInterpreter.runModel2(context, features, userBpm, userBreathingPattern)
        }

        // ê²°ê³¼ ë¸Œë¡œë“œìºìŠ¤íŠ¸
        val intent = Intent("PREDICTION_UPDATE")
        intent.putExtra("result", finalPrediction)
        intent.addFlags(Intent.FLAG_ACTIVITY_NEW_TASK)
        context.sendBroadcast(intent)

        Log.d("AudioRecorder", "ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼: $finalPrediction")
    }

    companion object {
        private const val SAMPLE_RATE = 16000
        private const val RECORD_SECONDS = 2

        private const val BUFFER_SIZE: Int =
            com.temrun_finalprojects.breathing.audio.AudioRecorder.Companion.SAMPLE_RATE * com.temrun_finalprojects.breathing.audio.AudioRecorder.Companion.RECORD_SECONDS
    }
}

